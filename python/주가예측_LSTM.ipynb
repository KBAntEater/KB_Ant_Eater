{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db23811e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ex:20221026) >> 20221026\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "import yfinance as yf\n",
    "from pykrx import stock\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import LSTM\n",
    "\n",
    "def make_dataset(data, label, window_size=20):\n",
    "    feature_list = []\n",
    "    label_list = []\n",
    "    for i in range(len(data) - window_size):\n",
    "        feature_list.append(np.array(data.iloc[i:i+window_size]))\n",
    "        label_list.append(np.array(label.iloc[i+window_size]))\n",
    "    return np.array(feature_list), np.array(label_list)\n",
    "\n",
    "df_pred = pd.DataFrame(columns = ['date','s_ticker','s_name','predict'])\n",
    "\n",
    "names = ['교보증권', 'DGB금융지주', 'BNK금융지주', '효성', '부국증권', '현대차증권', '롯데하이마트', '광주신세계', '현대홈쇼핑',\n",
    "         'GS리테일', '화승인더', 'HDC', '신라교역', '대한제당', '하이트진로홀딩스', '대상', '조흥', '삼양사', '동아타이어', '태영건설',\n",
    "         '한국가스공사', '금호석유', 'DL이앤씨', 'POSCO홀딩스', '한화투자증권', 'SK텔레콤', '지투알', 'KT', 'LG유플러스', '이노션',\n",
    "         '롯데하이마트', 'SK텔레콤', '휴비스', '한국주철관', 'KT&G', 'KT', 'HD현대', '세아베스틸지주', 'DGB금융지주', 'BNK금융지주',\n",
    "         '화성산업', '효성']\n",
    "today = input('(ex:20221026) >> ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2aad7fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "278/281 [============================>.] - ETA: 0s - loss: 0.0046\n",
      "Epoch 1: val_loss improved from inf to 0.00035, saving model to tmp_checkpoint.h5\n",
      "281/281 [==============================] - 3s 7ms/step - loss: 0.0046 - val_loss: 3.5306e-04\n",
      "Epoch 2/200\n",
      "275/281 [============================>.] - ETA: 0s - loss: 3.6203e-04\n",
      "Epoch 2: val_loss improved from 0.00035 to 0.00035, saving model to tmp_checkpoint.h5\n",
      "281/281 [==============================] - 2s 6ms/step - loss: 3.6382e-04 - val_loss: 3.4788e-04\n",
      "Epoch 3/200\n",
      "276/281 [============================>.] - ETA: 0s - loss: 3.1301e-04\n",
      "Epoch 3: val_loss improved from 0.00035 to 0.00030, saving model to tmp_checkpoint.h5\n",
      "281/281 [==============================] - 2s 6ms/step - loss: 3.1364e-04 - val_loss: 3.0162e-04\n",
      "Epoch 4/200\n",
      "275/281 [============================>.] - ETA: 0s - loss: 3.0288e-04\n",
      "Epoch 4: val_loss improved from 0.00030 to 0.00029, saving model to tmp_checkpoint.h5\n",
      "281/281 [==============================] - 2s 7ms/step - loss: 3.0071e-04 - val_loss: 2.9114e-04\n",
      "Epoch 5/200\n",
      "274/281 [============================>.] - ETA: 0s - loss: 2.8600e-04\n",
      "Epoch 5: val_loss improved from 0.00029 to 0.00028, saving model to tmp_checkpoint.h5\n",
      "281/281 [==============================] - 2s 6ms/step - loss: 2.8313e-04 - val_loss: 2.8164e-04\n",
      "Epoch 6/200\n",
      "275/281 [============================>.] - ETA: 0s - loss: 2.6467e-04\n",
      "Epoch 6: val_loss improved from 0.00028 to 0.00022, saving model to tmp_checkpoint.h5\n",
      "281/281 [==============================] - 2s 6ms/step - loss: 2.6218e-04 - val_loss: 2.1921e-04\n",
      "Epoch 7/200\n",
      "279/281 [============================>.] - ETA: 0s - loss: 2.7062e-04\n",
      "Epoch 7: val_loss did not improve from 0.00022\n",
      "281/281 [==============================] - 2s 6ms/step - loss: 2.7007e-04 - val_loss: 2.3955e-04\n",
      "Epoch 8/200\n",
      "278/281 [============================>.] - ETA: 0s - loss: 2.4803e-04\n",
      "Epoch 8: val_loss did not improve from 0.00022\n",
      "281/281 [==============================] - 2s 6ms/step - loss: 2.4736e-04 - val_loss: 2.2348e-04\n",
      "Epoch 9/200\n",
      "277/281 [============================>.] - ETA: 0s - loss: 2.4254e-04\n",
      "Epoch 9: val_loss improved from 0.00022 to 0.00020, saving model to tmp_checkpoint.h5\n",
      "281/281 [==============================] - 2s 6ms/step - loss: 2.4040e-04 - val_loss: 2.0460e-04\n",
      "Epoch 10/200\n",
      "277/281 [============================>.] - ETA: 0s - loss: 2.3261e-04\n",
      "Epoch 10: val_loss improved from 0.00020 to 0.00020, saving model to tmp_checkpoint.h5\n",
      "281/281 [==============================] - 2s 6ms/step - loss: 2.3142e-04 - val_loss: 1.9514e-04\n",
      "Epoch 11/200\n",
      "281/281 [==============================] - ETA: 0s - loss: 2.2617e-04\n",
      "Epoch 11: val_loss did not improve from 0.00020\n",
      "281/281 [==============================] - 2s 7ms/step - loss: 2.2617e-04 - val_loss: 1.9623e-04\n",
      "Epoch 12/200\n",
      "275/281 [============================>.] - ETA: 0s - loss: 2.3348e-04\n",
      "Epoch 12: val_loss did not improve from 0.00020\n",
      "281/281 [==============================] - 2s 6ms/step - loss: 2.3181e-04 - val_loss: 1.9779e-04\n",
      "Epoch 13/200\n",
      "274/281 [============================>.] - ETA: 0s - loss: 2.0994e-04\n",
      "Epoch 13: val_loss improved from 0.00020 to 0.00018, saving model to tmp_checkpoint.h5\n",
      "281/281 [==============================] - 2s 6ms/step - loss: 2.0948e-04 - val_loss: 1.8419e-04\n",
      "Epoch 14/200\n",
      "280/281 [============================>.] - ETA: 0s - loss: 2.0892e-04\n",
      "Epoch 14: val_loss did not improve from 0.00018\n",
      "281/281 [==============================] - 2s 6ms/step - loss: 2.0943e-04 - val_loss: 2.0553e-04\n",
      "Epoch 15/200\n",
      "278/281 [============================>.] - ETA: 0s - loss: 2.1609e-04\n",
      "Epoch 15: val_loss improved from 0.00018 to 0.00018, saving model to tmp_checkpoint.h5\n",
      "281/281 [==============================] - 2s 7ms/step - loss: 2.1505e-04 - val_loss: 1.7696e-04\n",
      "Epoch 16/200\n",
      "275/281 [============================>.] - ETA: 0s - loss: 2.0553e-04\n",
      "Epoch 16: val_loss did not improve from 0.00018\n",
      "281/281 [==============================] - 2s 6ms/step - loss: 2.0720e-04 - val_loss: 1.8430e-04\n",
      "Epoch 17/200\n",
      "278/281 [============================>.] - ETA: 0s - loss: 2.0426e-04\n",
      "Epoch 17: val_loss did not improve from 0.00018\n",
      "281/281 [==============================] - 2s 6ms/step - loss: 2.0604e-04 - val_loss: 2.0195e-04\n",
      "Epoch 18/200\n",
      "272/281 [============================>.] - ETA: 0s - loss: 2.1095e-04\n",
      "Epoch 18: val_loss did not improve from 0.00018\n",
      "281/281 [==============================] - 2s 6ms/step - loss: 2.1148e-04 - val_loss: 2.0502e-04\n",
      "Epoch 19/200\n",
      "273/281 [============================>.] - ETA: 0s - loss: 2.0373e-04\n",
      "Epoch 19: val_loss did not improve from 0.00018\n",
      "281/281 [==============================] - 2s 6ms/step - loss: 2.0121e-04 - val_loss: 1.8614e-04\n",
      "Epoch 20/200\n",
      "278/281 [============================>.] - ETA: 0s - loss: 1.9668e-04\n",
      "Epoch 20: val_loss did not improve from 0.00018\n",
      "281/281 [==============================] - 2s 6ms/step - loss: 1.9748e-04 - val_loss: 2.4194e-04\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "                  date s_ticker s_name      predict\n",
      "0  2022-10-26 00:00:00   030610   교보증권  5594.848633\n"
     ]
    }
   ],
   "source": [
    "s_name = names[0]\n",
    "conn = pymysql.connect (host='localhost',user ='ant',password='roal',db='antdb',charset='utf8')\n",
    "cur = conn.cursor()\n",
    "sql = f\"select * from stock_db where s_name='{s_name}'\" \n",
    "cur.execute(sql)\n",
    "df = pd.DataFrame(cur.fetchall(), columns=['ticker','name','date','open','high','low','close','volume','kospi','kospi200','kospi100','kospi50','IXIC','SnP500','HSI'])\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "s_ticker = df['ticker'][0]\n",
    "\n",
    "\n",
    "scale_cols = ['open','high','low','volume','kospi','kospi200','IXIC','SnP500','HSI']\n",
    "\n",
    "scaler_x = MinMaxScaler().fit(df[scale_cols])\n",
    "scaled_x = scaler_x.transform(df[scale_cols])\n",
    "df_scaled_x = pd.DataFrame(scaled_x)\n",
    "\n",
    "scaler_y = MinMaxScaler().fit(df['close'].values.reshape(-1,1))\n",
    "scaled_y = scaler_y.transform(df['close'].values.reshape(-1,1))\n",
    "df_scaled_x.columns = scale_cols\n",
    "\n",
    "train = df_scaled_x.copy()\n",
    "train['close'] = scaled_y\n",
    "\n",
    "feature_cols = ['open','high','low','volume','kospi','kospi200','IXIC','SnP500','HSI']\n",
    "label_cols = ['close']\n",
    "\n",
    "train_feature = train[feature_cols]\n",
    "train_label = train[label_cols]\n",
    "\n",
    "# train dataset\n",
    "train_feature, train_label = make_dataset(train_feature, train_label, 20)\n",
    "\n",
    "# train, validation set 생성\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train_feature, train_label, test_size=0.2)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(16, \n",
    "               input_shape=(train_feature.shape[1], train_feature.shape[2]), \n",
    "               activation='relu', \n",
    "               return_sequences=False)\n",
    "          )\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
    "checkpoint = ModelCheckpoint('tmp_checkpoint.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "model.fit(x_train, y_train, \n",
    "                epochs=200, \n",
    "                batch_size=16,\n",
    "                validation_data=(x_valid, y_valid),\n",
    "                callbacks=[early_stop, checkpoint])\n",
    "\n",
    "\n",
    "real = stock.get_market_ohlcv_by_date(fromdate=\"20220101\", todate=today, ticker=f'{s_ticker}')[-20:].drop('종가',axis=1)\n",
    "kospi = stock.get_index_fundamental(\"20220101\", today, \"1001\")[['종가']][-20:]\n",
    "kospi200 = stock.get_index_fundamental(\"20220101\", today, \"1028\")[['종가']][-20:]\n",
    "# kospi100 = stock.get_index_fundamental(\"20220101\", today, \"1034\")[['종가']][-20:]\n",
    "# kospi50 = stock.get_index_fundamental(\"20220101\", today, \"1035\")[['종가']][-20:]\n",
    "IXIC = yf.download('^IXIC',start = '2022-01-01', end=f'{today[:4]}-{today[4:6]}-{today[6:]}')[['Close']][-20:]\n",
    "SnP500 = yf.download('^GSPC',start = '2022-01-01', end=f'{today[:4]}-{today[4:6]}-{today[6:]}')[['Close']][-20:]\n",
    "HSI = yf.download('^GSPC',start = '2022-01-01', end=f'{today[:4]}-{today[4:6]}-{today[6:]}')[['Close']][-20:]\n",
    "\n",
    "real['kospi'] = list(kospi['종가'])\n",
    "real['kospi200'] = list(kospi200['종가'])\n",
    "# real['kospi100'] = list(kospi100['종가'])\n",
    "# real['kospi50'] = list(kospi50['종가'])\n",
    "real['IXIC'] = list(IXIC['Close'])\n",
    "real['SnP500'] = list(SnP500['Close'])\n",
    "real['HSI'] = list(HSI['Close'])\n",
    "\n",
    "real = scaler_x.transform(real)\n",
    "model_inputs = np.array([real])\n",
    "\n",
    "pred = model.predict(model_inputs)\n",
    "pred = scaler_y.inverse_transform(pred)\n",
    "\n",
    "ex = pd.DataFrame({'date':[pd.to_datetime(today)],'s_ticker':[s_ticker],'s_name':[s_name],'predict':[pred[0][0]]})\n",
    "df_pred = df_pred.append(ex,ignore_index=True)\n",
    "print(df_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
